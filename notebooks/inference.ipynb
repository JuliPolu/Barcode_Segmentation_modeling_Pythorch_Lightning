{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e377b576",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bb7090",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from lightning_module import SegmentModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f100b5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEVICE = 'cuda:0' if torch.cuda.is_available else 'cpu'\n",
    "DEVICE = 'cpu'\n",
    "DATA_PATH = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247496b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем модель\n",
    "\n",
    "checkpoint_name = '..\\\\experiments\\\\unet_resnet34_d_f_320\\\\epoch_epoch=27-val_IoU=0.889.ckpt'\n",
    "module = SegmentModule.load_from_checkpoint(checkpoint_name, map_location=torch.device('cpu'))\n",
    "\n",
    "_ = module.eval()\n",
    "_ = module.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8cfc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем данные\n",
    "df = pd.read_csv('..\\\\data\\\\df_test.csv')\n",
    "names = list(df.columns[1:])\n",
    "names\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77b5237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# препроцессинг данных \n",
    "from augmentations import get_transforms\n",
    "test_transforms = get_transforms(width=320, height=320, encoder = 'resnet34', augmentations=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cb82c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_postprocesing(prob_mask, threshold):\n",
    "    mask = (prob_mask > threshold).astype(np.uint8)\n",
    "    mask = mask.transpose(1, 2, 0)\n",
    "    num_labels, labels_im = cv2.connectedComponents(mask)\n",
    "    max_size = 0\n",
    "    max_label = 0\n",
    "    for label in range(1, num_labels):\n",
    "        component = (labels_im == label).astype(np.uint8)\n",
    "        size = cv2.countNonZero(component)\n",
    "        if size > max_size:\n",
    "            max_size = size\n",
    "            max_label = label\n",
    "\n",
    "    largest_component_mask = (labels_im == max_label).astype(np.uint8)\n",
    "\n",
    "    largest_component_mask = (largest_component_mask > 0).astype(np.uint8)\n",
    "    return largest_component_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e4a5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 10\n",
    "image_name = os.path.normpath(os.path.join(DATA_PATH, df[\"filename\"][idx]))\n",
    "image = cv2.imread(image_name)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "procecces_image = test_transforms(image=image)['image']\n",
    "procecces_image = procecces_image.float()\n",
    "with torch.no_grad():\n",
    "    prob_mask = torch.sigmoid(module(procecces_image[None].to(DEVICE)))[0].cpu().numpy()\n",
    "    \n",
    "mask = mask_postprocesing(prob_mask, 0.5)\n",
    "procecces_image = procecces_image.permute(1, 2, 0)\n",
    "plt.subplot(1,3,1)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(procecces_image.squeeze())\n",
    "plt.subplot(1,3,2)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(prob_mask.squeeze(), cmap='gray')\n",
    "plt.subplot(1,3,3)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(mask.squeeze(), cmap='gray')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f91407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as tp\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import albumentations as albu\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import argparse \n",
    "import segmentation_models_pytorch as smp\n",
    "import onnxruntime as ort\n",
    "\n",
    "MODEL_THRESHOLD = 0.4\n",
    "TARGET_IMAGE_SIZE = (256, 256)\n",
    "MODEL_ENCODER = 'resnet34'\n",
    "PRETRAINED_WEIGHTS = 'imagenet'\n",
    "\n",
    "def mask_postprocesing(prob_mask, threshold):\n",
    "    mask = (prob_mask > threshold).astype(np.uint8)\n",
    "    mask = mask.transpose(1, 2, 0)\n",
    "    num_labels, labels_im = cv2.connectedComponents(mask)\n",
    "    max_size = 0\n",
    "    max_label = 0\n",
    "    for label in range(1, num_labels):\n",
    "        component = (labels_im == label).astype(np.uint8)\n",
    "        size = cv2.countNonZero(component)\n",
    "        if size > max_size:\n",
    "            max_size = size\n",
    "            max_label = label\n",
    "\n",
    "    largest_component_mask = (labels_im == max_label).astype(np.uint8)\n",
    "\n",
    "    largest_component_mask = (largest_component_mask > 0).astype(np.uint8)\n",
    "    return largest_component_mask\n",
    "\n",
    "\n",
    "def preprocess_image(image: np.ndarray, target_image_size: tp.Tuple[int, int]) -> torch.Tensor:\n",
    "\n",
    "    image = image.astype(np.float32)\n",
    "    \n",
    "    processing_smp = smp.encoders.get_preprocessing_fn(MODEL_ENCODER, pretrained = PRETRAINED_WEIGHTS)\n",
    "\n",
    "    preprocess = albu.Compose(\n",
    "            [\n",
    "                albu.Resize(height=target_image_size, width=target_image_size),\n",
    "                albu.Lambda(image=processing_smp),\n",
    "                ToTensorV2(),\n",
    "            ]\n",
    "    )\n",
    "    image_array = preprocess(image=image)['image'] \n",
    "    image_array = image_array.float().numpy() \n",
    "    \n",
    "    return image_array\n",
    "\n",
    "def run_inference(session, input_data):\n",
    "    input_name = session.get_inputs()[0].name\n",
    "\n",
    "    outputs = session.run(None, {input_name: input_data})\n",
    "    return outputs\n",
    "\n",
    "image_path = \"../data/images/0.jpg\"\n",
    "img = cv2.imread(image_path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = preprocess_image(img, 256)\n",
    "\n",
    "ONNX_MODEL_NAME = '../model_weights/onnx_model.onnx'\n",
    "\n",
    "ort_session = ort.InferenceSession(\n",
    "    ONNX_MODEL_NAME,\n",
    "    providers=['CPUExecutionProvider',],\n",
    ")\n",
    "\n",
    "# Run inference\n",
    "output = run_inference(ort_session, img[None])\n",
    "prob_mask = torch.sigmoid(torch.tensor(output[0]))[0].numpy()\n",
    "mask = mask_postprocesing(prob_mask, MODEL_THRESHOLD)\n",
    "\n",
    "procecces_image = img.transpose(1, 2, 0)\n",
    "plt.subplot(1,3,1)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(procecces_image.squeeze())\n",
    "plt.subplot(1,3,2)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(prob_mask.squeeze(), cmap='gray')\n",
    "plt.subplot(1,3,3)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(mask.squeeze(), cmap='gray')\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
